# üìò Documentation Technique : Code Annot√© & Expliqu√©

Ce document pr√©sente le code source des composants critiques avec une explication d√©taill√©e pour chaque bloc. C'est le guide ultime pour comprendre la m√©canique interne.

---

# 1. `MCP_Client.py` : Le Gestionnaire de Connexions

Ce fichier g√®re les connexions asynchrones aux serveurs MCP.

### üîí Gestion de la Concurrence et √âtat

```python
class UniversalMCPClient:
    def __init__(self):
        self._servers: Dict[str, ServerInfo] = {}
        self._lock = asyncio.Lock()
        self._closed = False
```
**Explication :**
*   `self._servers` : Notre "registre" en m√©moire. Il stocke les objets `ServerInfo` (qui contiennent la session active) pour chaque serveur connect√©.
*   `self._lock = asyncio.Lock()` : **Crucial**. C'est un "Mutex" (Mutual Exclusion).
    *   **Pourquoi ?** Dans un environnement asynchrone, plusieurs t√¢ches peuvent s'ex√©cuter "en m√™me temps" (entrelac√©es). Si une t√¢che essaie de lire `_servers` pendant qu'une autre le modifie (ex: suppression d'un serveur), cela peut cr√©er des bugs al√©atoires ou des crashs.
    *   Le verrou garantit qu'une seule t√¢che touche √† `_servers` √† la fois.

### üîå La Connexion (Le C≈ìur du R√©acteur)

```python
async def _connect_server(self, config: ServerConfig) -> ServerInfo:
    stack = AsyncExitStack()
    
    try:
        # ... (choix du transport) ...
        if config.transport == "stdio":
            session = await self._connect_stdio(config, stack)
        
        await session.initialize()
        tools_response = await session.list_tools()
        
        return ServerInfo(..., stack=stack)
```
**Explication :**
*   `stack = AsyncExitStack()` : C'est l'outil magique de Python pour g√©rer les ressources.
    *   Une connexion MCP, c'est plusieurs couches : Processus -> Flux Entr√©e -> Flux Sortie -> Session.
    *   Chaque couche doit √™tre ferm√©e proprement.
    *   `AsyncExitStack` empile ces contextes. Si on quitte la fonction sans erreur, la pile reste "vivante" (les connexions restent ouvertes). On stocke cette `stack` dans `ServerInfo` pour pouvoir la fermer plus tard (`stack.aclose()`).
*   `await session.initialize()` : Le "Handshake". On dit "Bonjour" au serveur MCP pour v√©rifier qu'il parle la m√™me langue (protocole) que nous.
*   `await session.list_tools()` : On r√©cup√®re **tout de suite** la liste des outils. On ne veut pas faire un appel r√©seau √† chaque fois qu'on a besoin de savoir si un outil existe.

### üõ†Ô∏è Appel d'Outil S√©curis√©

```python
async def call_tool(self, server_name, tool_name, arguments, timeout=None):
    async with self._lock:
        server_info = self._servers.get(server_name)
        # ... v√©rifications ...

    if timeout:
        result = await asyncio.wait_for(
            server_info.session.call_tool(tool_name, arguments or {}),
            timeout=timeout
        )
    else:
        result = await server_info.session.call_tool(...)
```
**Explication :**
*   `async with self._lock` : On prot√®ge la lecture. On s'assure que le serveur ne va pas dispara√Ætre (√™tre supprim√©) pendant qu'on r√©cup√®re ses infos.
*   `asyncio.wait_for(..., timeout=timeout)` : **S√©curit√©**.
    *   Si un outil (ex: un script Python mal cod√©) boucle √† l'infini, on ne veut pas bloquer notre serveur principal.
    *   Si le d√©lai est d√©pass√©, Python tue la t√¢che et l√®ve une erreur `TimeoutError`, ce qui nous permet de reprendre la main.

---

# 2. `ChatManager.py` : L'Intelligence Agentique

Ce fichier g√®re la conversation et la boucle de d√©cision (ReAct).

### üîÑ La Boucle Principale (The Agent Loop)

```python
async def _process_conversation_loop(self) -> str:
    iteration = 0
    while iteration < self.max_iterations:
        iteration += 1
        
        # 1. Appel √† l'IA
        response_message = await self._call_llm()
        
        # 2. Ajout de la r√©ponse √† l'historique
        self.conversation_history.append(assistant_message)
        
        # 3. V√©rification : L'IA veut-elle utiliser des outils ?
        if assistant_message.tool_calls:
            # Ex√©cution des outils
            tool_results = await self._execute_tool_calls(assistant_message.tool_calls)
            
            # Ajout des r√©sultats √† l'historique
            for result in tool_results:
                self.conversation_history.append(tool_message)
            
            # 4. REBOUCLAGE
            continue
            
        # Sinon, on a fini
        return assistant_message.content
```
**Explication :**
*   `while iteration < self.max_iterations` : On emp√™che l'IA de tourner en rond ind√©finiment (s√©curit√©).
*   `if assistant_message.tool_calls` : C'est ici que l'IA devient "active". Elle ne r√©pond pas juste du texte, elle envoie une commande structur√©e (JSON) pour dire "Ex√©cute l'outil X".
*   `continue` : **La ligne la plus importante**.
    *   Au lieu de s'arr√™ter et de r√©pondre √† l'utilisateur, on **repart au d√©but de la boucle**.
    *   On rappelle l'LLM avec un historique enrichi : [Question User] -> [Pens√©e IA] -> [R√©sultat Outil].
    *   L'LLM peut alors analyser le r√©sultat et formuler sa r√©ponse finale.

### ‚ö° Ex√©cution Parall√®le

```python
async def _execute_tool_calls(self, tool_calls: List[ToolCall]) -> List[ToolResult]:
    # Cr√©ation des t√¢ches
    tasks = [
        tool_call.execute(self.mcp_client)
        for tool_call in tool_calls
    ]
    
    # Ex√©cution simultan√©e
    results = await asyncio.gather(*tasks, return_exceptions=True)
```
**Explication :**
*   Si l'IA demande 3 outils (ex: "M√©t√©o Paris", "M√©t√©o Londres", "M√©t√©o Tokyo"), on ne les lance pas l'un apr√®s l'autre.
*   `asyncio.gather` les lance **tous en m√™me temps**.
*   Si "M√©t√©o Paris" prend 2s, "Londres" 1s et "Tokyo" 3s, le tout prendra 3s (le plus long) au lieu de 6s (la somme). C'est un gain de performance √©norme.

---

# 3. `app.py` : Le Serveur Web (FastAPI)

Ce fichier fait le lien entre le web et notre logique.

### üíâ Injection de D√©pendance (La Session DB)

```python
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```
**Explication :**
*   C'est un "Context Manager" sous forme de g√©n√©rateur.
*   `yield db` : Donne la connexion √† la fonction qui en a besoin.
*   `finally: db.close()` : **Garantie absolue**. Quoi qu'il arrive (succ√®s, erreur, crash dans la fonction), ce bloc sera ex√©cut√©. On est s√ªr √† 100% de ne jamais laisser une connexion ouverte ("leak"), ce qui finirait par planter la base de donn√©es.

### üß† Reconstruction de l'√âtat (Stateless Architecture)

```python
@app.post("/chat/{session_id}")
async def chat(session_id: str, request: ChatRequest, db: Session = Depends(get_db)):
    
    # 1. R√©cup√©ration de la session
    db_session = db.query(SessionModel).filter(SessionModel.id == session_id).first()
    
    # 2. Reconstruction de l'historique
    history = []
    for msg in db_session.messages:
        history.append(Message(...))
    
    # 3. R√©surrection du ChatManager
    chat_manager = ChatManager(mcp_client=mcp_client, history=history)
```
**Explication :**
*   Le serveur ne garde **rien** en m√©moire vive (RAM) concernant la conversation.
*   √Ä chaque fois que vous envoyez un message :
    1.  On va chercher tout l'historique dans le disque dur (SQLite).
    2.  On recr√©e un cerveau (`ChatManager`) tout neuf et on lui injecte ces souvenirs.
    3.  Il traite le message.
    4.  On sauvegarde les nouveaux souvenirs.
    5.  On d√©truit le cerveau.
*   **Avantage** : Si le serveur red√©marre, on ne perd rien. Si on a 1 million d'utilisateurs, on ne sature pas la RAM.

### üíæ Sauvegarde Diff√©rentielle (Optimisation)

```python
    # Avant le traitement
    initial_history_count = len(history)
    
    # ... Traitement (l'IA r√©fl√©chit, appelle des outils, ajoute des messages) ...
    
    # Apr√®s le traitement
    new_messages = chat_manager.conversation_history[initial_history_count:]
    
    for msg in new_messages:
        db.add(MessageModel(...))
    
    db.commit()
```
**Explication :**
*   On ne sauvegarde pas tout l'historique √† chaque fois (ce serait trop lent).
*   On regarde combien de messages on avait au d√©but (`initial_history_count`).
*   On ne prend que les messages qui ont √©t√© ajout√©s **apr√®s** cet index (`new_messages`).
*   `db.commit()` : On valide la transaction. C'est "tout ou rien". Soit tous les nouveaux messages sont sauv√©s, soit aucun (en cas d'erreur), pour ne pas corrompre la base.
